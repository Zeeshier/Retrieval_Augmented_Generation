{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain_core.documents import Document\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asif Computer\\AppData\\Local\\Temp\\ipykernel_4416\\2987287500.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed_model = HuggingFaceEmbeddings(model_name='BAAI/bge-small-en-v1.5')\n",
      "c:\\Users\\Asif Computer\\anaconda3\\envs\\conda\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedding model with BAAI/bge-small-en-v1.5\n",
    "embed_model = HuggingFaceEmbeddings(model_name='BAAI/bge-small-en-v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PDF document using PyPDFLoader\n",
    "loaders = PyPDFLoader(\"AI_Engineer_Roadmap.pdf\")\n",
    "\n",
    "# Extract pages from the loaded PDF\n",
    "pages = loaders.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'AI_Engineer_Roadmap.pdf', 'page': 9}, page_content=' \\n   \\ncodebasics.io  \\n \\n10 \\no Track B (Affordable Fees):  \\n▪ Included in  the above Master Machine Learning for Data Science & AI  \\n \\nWeek 23, 24: Machine Learning Projects  with Deployment       \\n \\n• You need to finish two end to end ML projects. One on Regression , the other on \\nClassification  \\n• Regression Project: Bangalore property price prediction  \\no YouTube playlist link: https://bit.ly/3ivycWr  \\no Project covers following  \\n▪ Data cleaning  \\n▪ Feature engineering  \\n▪ Model building and hyper parameter tuning  \\n▪ Write flask server as a web backend  \\n▪ Building website for price prediction  \\n▪ Deployment to AWS  \\n• Classification Project: Sports celebrity image classification  \\no YouTube playlist link: https://bit.ly/3ioaMSU  \\no Project covers following  \\n▪ Data collection and data cleaning  \\n▪ Feature engineering and model training  \\n▪ Flask server as a web backend  \\n▪ Building website and deployment  \\n• ATS Resume Preparation  \\no Resumes are dying but not dead yet. Focus more on online presence.  \\no Here is the resume tips video along with some templates you can use for your \\ndata analyst resume: https://www.youtube.com/watch?v=buQSI8NLOMw  \\no Use this checklist to ensure you have the right ATS Resume:  Check here.  \\n \\n \\n• Portfolio Building Resources:  \\nYou need a portfolio website in 2024. You can build your portfolio by using these free \\nresources.  \\n• GitHub  \\no Upload your projects with code on github and using github.io create a \\nportfolio website  \\no Sample portfolio website: http://rajag0pal.github.io/  \\n ')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Document into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MetaData preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store processed document chunks\n",
    "doc_list = []\n",
    "\n",
    "# Iterate over each page in the extracted pages\n",
    "for page in pages:\n",
    "    # Split the page content into smaller chunks\n",
    "    pg_split = text_splitter.split_text(page.page_content)\n",
    "\n",
    "    # Iterate over each chunk and create Document objects\n",
    "    for pg_sub_split in pg_split:\n",
    "        # Metadata for each chunk, including source and page number\n",
    "        metadata = {\"source\": \"AI Roadmap\", \"page_no\": page.metadata[\"page\"] + 1}\n",
    "\n",
    "        # Create a Document object with content and metadata\n",
    "        doc_string = Document(page_content=pg_sub_split, metadata=metadata)\n",
    "\n",
    "        # Append the Document object to the list\n",
    "        doc_list.append(doc_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'AI Roadmap', 'page_no': 10}, page_content='codebasics.io  \\n \\n10 \\no Track B (Affordable Fees):  \\n▪ Included in  the above Master Machine Learning for Data Science & AI  \\n \\nWeek 23, 24: Machine Learning Projects  with Deployment       \\n \\n• You need to finish two end to end ML projects. One on Regression , the other on \\nClassification  \\n• Regression Project: Bangalore property price prediction  \\no YouTube playlist link: https://bit.ly/3ivycWr  \\no Project covers following  \\n▪ Data cleaning  \\n▪ Feature engineering  \\n▪ Model building and hyper parameter tuning  \\n▪ Write flask server as a web backend  \\n▪ Building website for price prediction  \\n▪ Deployment to AWS  \\n• Classification Project: Sports celebrity image classification  \\no YouTube playlist link: https://bit.ly/3ioaMSU  \\no Project covers following  \\n▪ Data collection and data cleaning  \\n▪ Feature engineering and model training  \\n▪ Flask server as a web backend  \\n▪ Building website and deployment  \\n• ATS Resume Preparation  \\no Resumes are dying but not dead yet. Focus more on online presence.  \\no Here is the resume tips video along with some templates you can use for your \\ndata analyst resume: https://www.youtube.com/watch?v=buQSI8NLOMw  \\no Use this checklist to ensure you have the right ATS Resume:  Check here.  \\n \\n \\n• Portfolio Building Resources:  \\nYou need a portfolio website in 2024. You can build your portfolio by using these free \\nresources.  \\n• GitHub  \\no Upload your projects with code on github and using github.io create a \\nportfolio website')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qdrant Vectore Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qdrant Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_url = \"\"\n",
    "qdrant_key = \"\"\n",
    "collection_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize QdrantVectorStore with documents and embedding model\n",
    "qdrant = QdrantVectorStore.from_documents(\n",
    "    doc_list,                # List of Document objects to be stored in the vector store\n",
    "    embed_model,             # Embedding model used to convert documents into vectors\n",
    "    url=qdrant_url,          # URL for the Qdrant service\n",
    "    api_key=qdrant_key,      # API key for accessing the Qdrant service\n",
    "    collection_name=collection_name  # Name of the collection to store the vectors in\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is Ai roadmap?\"\n",
    "\n",
    "# Retrieve relevant documents\n",
    "results = qdrant.similarity_search(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'AI Roadmap', 'page_no': 11, '_id': 'e1ec305a-f62b-4c51-b272-90fcb26bfa90', '_collection_name': 'AI_Roadmap'}, page_content='codebasics.io  \\n \\n11 \\n• Linktree  \\no Helpful to add multiple links in one page.  \\n \\n• Assignment  \\no In above two projects make following changes  \\n☐ Use FastAPI  instead of flask . FastAPI tutorial: https://youtu.be/Wr1JjhTt1Xg  \\n☐ Regression project : Instead of property prediction, take any other project \\nof your interest from Kaggle for regress ion \\n☐ Classification project : Instead of sports celebrity classification, take any \\nother project of your interest from Kaggle for classification and build end to \\nend solution along with deployment to AWS or Azure  \\n     ☐ Add a link of your projects in your resume and LinkedIn.  \\n(Tag Codebasics, Dhaval Patel and Hemanand Vadivel with the hashtag \\n#dsroadmap24 so we can engage to increase your visibility)  \\n \\n \\nWeek 25, 26, 27 : Deep Learning           \\n \\n• Topics  \\no What is a neural network? Forward propagation, back propagation  \\no Building multilayer perceptron  \\no Special neural network architectures  \\n▪ Convolutional neural network (CNN)  \\n▪ Sequence models: RNN, LSTM  \\n \\n• Learning Resources  \\no Deep Learning playlist  (tensorflow) : https://bit.ly/3vOZ3zV  \\no Deep learning playlist (pytorch): https://bit.ly/3TzDbWp  \\no End to end potato disease  classification project: https://bit.ly/3QzkVJi  \\n \\n• Assignment  \\n☐ Instead of potato plant images use tomato plant images or some other image \\nclassification dataset . \\n☐ Deploy to Azure instead of GCP .')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'codebasics.io  \\n \\n1 \\nAI Engineer Roadmap for Beginners  \\nFollowing is the roadmap  to learning  AI Engineer  (also known as ML Engineer ) skills for a total \\nbeginner. It includes FREE learning resources for technical skills (or tool skills) and soft (or core) skills  \\n          \\nPrerequisites : You must have skills or interests  to build skills in Coding and Math. Without these two \\nyou cannot become an AI engineer.  \\nTotal Duration: 8 Months  (4 hours  of study Every Day ) \\nAlso, AI Engineer = Data Scientist + Software Engineer  \\n \\n \\nWeek 0: Do Proper Research and protect yourself from SCAMS.  \\n \\n Unfortunately, a lot of systematic scams are happening in ed tech, especially in the \\ndata field where aspirants are provided with false promises like a 100% job guarantee or \\ntrapped into “Masterclasses” which are nothing but sales pitches to upsell their l ow-grade \\ncourses at exorbitant prices. You need to do complete research about the market and \\nmentors before starting your journey. Providing you the links to a few posts that we have \\nmade in this regard which will support your research.  \\n \\nEven though these  posts are NOT  sufficient, do your additional research.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinecone Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=\"\"\n",
    "index_name=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Upsertion in Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore as lang_pinecone\n",
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert documents into vectors using LangPinecone\n",
    "vector = lang_pinecone.from_documents(\n",
    "    doc_list,                # List of Document objects to be converted into vectors\n",
    "    embed_model,             # Embedding model used for generating vector representations\n",
    "    index_name=index_name    # Name of the Pinecone index where vectors will be stored\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query to search for relevant information\n",
    "query = \"Classification\"\n",
    "\n",
    "# Perform similarity search to find the top 5 most relevant results\n",
    "pinecone_results = vector.similarity_search(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='463daf4b-cc13-422f-ad00-669a8cc79b19', metadata={'page_no': 8.0, 'source': 'AI Roadmap'}, page_content='codebasics.io  \\n \\n8 \\nWeek 17: Exploratory Data Analysis (EDA)           \\n \\n• Exploratory Data Analysis (EDA)  \\no https://www.kaggle.com/code?searchQuery=exploratory+data+analysis  \\no Use the above link to search for exploratory data analysis notebooks.  \\no Practice EDA using at least 3 datasets.  \\n▪ e.g. https://www.kaggle.com/datasets/rishabhkarn/ipl -auction -\\n2023/data  \\n \\n• Assignment  \\n☐ Perform EDA (Exploratory data analysis on at least 2 additional datasets  on \\nKaggle)  \\n \\nWeek 18, 19, 20, 21 : Machine Learning          \\n \\n• Machine Learning : Preprocessing  \\no Handling NA values , outlier treatment, data normalization  \\no One hot encoding, label encoding  \\no Feature engineering  \\no Train test split  \\no Cross validation  \\n• Machine Learning: Model  Building  \\no Types of ML: Supervised, Unsupervised  \\no Supervised: Regression vs Classification  \\no Linear models  \\n▪ Linear regression, logistic regression  \\n▪ Gradient descent  \\no Nonlinear models ( tree-based  models)  \\n▪ Decision tree  \\n▪ Random forest  \\n▪ XGBoost  \\no Model evaluation  \\n▪ Regression: Mean Squared Error, Mean Absolute Error, MAPE  \\n▪ Classification: Accuracy, Precision -Recall, F1 Score, ROC Curve, \\nConfusion matrix  \\no Hyperparameter tunning: GridSearchCV, RandomSearchCV'),\n",
       " Document(id='5adf4f73-1912-466b-93b4-9c355d8c1961', metadata={'page_no': 11.0, 'source': 'AI Roadmap'}, page_content='codebasics.io  \\n \\n11 \\n• Linktree  \\no Helpful to add multiple links in one page.  \\n \\n• Assignment  \\no In above two projects make following changes  \\n☐ Use FastAPI  instead of flask . FastAPI tutorial: https://youtu.be/Wr1JjhTt1Xg  \\n☐ Regression project : Instead of property prediction, take any other project \\nof your interest from Kaggle for regress ion \\n☐ Classification project : Instead of sports celebrity classification, take any \\nother project of your interest from Kaggle for classification and build end to \\nend solution along with deployment to AWS or Azure  \\n     ☐ Add a link of your projects in your resume and LinkedIn.  \\n(Tag Codebasics, Dhaval Patel and Hemanand Vadivel with the hashtag \\n#dsroadmap24 so we can engage to increase your visibility)  \\n \\n \\nWeek 25, 26, 27 : Deep Learning           \\n \\n• Topics  \\no What is a neural network? Forward propagation, back propagation  \\no Building multilayer perceptron  \\no Special neural network architectures  \\n▪ Convolutional neural network (CNN)  \\n▪ Sequence models: RNN, LSTM  \\n \\n• Learning Resources  \\no Deep Learning playlist  (tensorflow) : https://bit.ly/3vOZ3zV  \\no Deep learning playlist (pytorch): https://bit.ly/3TzDbWp  \\no End to end potato disease  classification project: https://bit.ly/3QzkVJi  \\n \\n• Assignment  \\n☐ Instead of potato plant images use tomato plant images or some other image \\nclassification dataset . \\n☐ Deploy to Azure instead of GCP .'),\n",
       " Document(id='f9e77761-d1aa-465f-9b7f-d196dac141e6', metadata={'page_no': 12.0, 'source': 'AI Roadmap'}, page_content='codebasics.io  \\n \\n12 \\nWeek 28, 29, 30 : NLP or Computer Vision  & GenAI  📃 \\n \\n• Many AI engineers  choose a specialized track which is either NLP or Computer vision. \\nYou don’t need to learn both.  \\n• Natural Language Processing (N LP) \\no Topics  \\n▪ Regex  \\n▪ Text presentation: Count vectorizer, TF -IDF, BOW, Word2Vec, \\nEmbeddings  \\n▪ Text classification: Naïve Bayes  \\n▪ Fundamentals of Spacy & NLTP library  \\n▪ One end to end project  \\no Learning Resources  \\n▪ NLP YouTube playlist: https://bit.ly/3XnjfEZ  \\n \\n• Comput er Vision (CV)  \\no Topics  \\n▪ Basic image processing techniques: Filtering, Edge Detection, Image \\nScaling, Rotation  \\n▪ Library to use: OpenCV  \\n▪ Convolutional Neural Networks (CNN) – Already covered in deep \\nlearning.  \\n▪ Data preprocessing, augmentation – Already covered in deep learning.  \\n• Assignment  \\n☐ NLP Track: Complete exercises in this playlist: https://bit.ly/3XnjfEZ  \\n \\nWeek 31, 32 : LLM & Langchain 📃 \\n \\n• Topics  \\no What is LLM, Vector database, Embeddings?  \\no RAG (Retrieval Augmented Generation)  \\no Langchain framework  \\n• Learning Resources  \\no Langchain, LLM playlist: https://bit.ly/3RYpxuw'),\n",
       " Document(id='65d9c9b1-e7d1-44eb-9fd7-7e59ce2f9682', metadata={'page_no': 2.0, 'source': 'AI Roadmap'}, page_content='codebasics.io  \\n \\n2 \\n• https://bit.ly/4at9Jaw  \\n• https://bit.ly/477IOOs  \\n• https://bit.ly/3GPD7dp  \\n \\n \\nWeek 1 and 2: Computer Science Fundamentals 💻 \\n \\n• Topics  \\no Data representation: Bits and Bytes, Storing text and numbers, Binary number \\nsystem.  \\no Basics of computer networks, IP addresses, Internet routing protocol  \\no UDP, TCP, HTTP, and The World Wide Web  \\no Programming basics: variables, strings, and numbers, if condition, loops  \\no Algorithm basics  \\n• Learning Resources  \\no Khan Academy  course: https://bit.ly/42DUXtW  \\no In the above course , only follow the first 4 sections (1) Digital Information (2) The \\nInternet (3) Programming (4) Algorithms . Completing the remaining sections is \\noptional . Do it if you have time and interest.  \\n \\nWeek 3 and 4: Beginners P ython                                                                \\n \\n• Topics  \\no Variables, Numbers, Strings  \\no Lists, Dictionaries, Sets, Tuples  \\no If condition, for loop  \\no Functions, Lambda Functions  \\no Modules  (pip install)  \\no Read, Write files \\no Exception handling  \\no Classes, Objects  \\n• Learning Resources  \\no Track A (Free)  \\n▪ Python Tutorials (Codebasics) on YouTube  (first 16  videos ) \\n- https://bit.ly/3X6CCC7  \\n▪ Corey’s Python Tutorials: https://bit.ly/3uqUgaZ  \\n▪ Codebasics python HINDI tutorials  \\n- https://bit.ly/3vmXrgw'),\n",
       " Document(id='6b13576f-ee1f-4630-bbb7-d1df433206c8', metadata={'page_no': 9.0, 'source': 'AI Roadmap'}, page_content='codebasics.io  \\n \\n9 \\no Unsupervised: K means, Hierarchical clustering, Dimensionality reduction \\n(PCA)  \\n \\n• Learning Resources  \\no Track  A \\n▪ YouTube playlist (more than 2 million views): https://bit.ly/3io5qqX  \\n▪ First 21 videos  \\n▪ Feature engineering playlist: https://bit.ly/3IFa3Yf  \\no Track B (Affordable Fees)  \\n▪ Master Machine Learning for Data Science & AI: This course takes you \\nfrom beginner to advanced levels, providing deep intuition on \\nalgorithms, engaging cinematic experiences, end -to-end projects, and \\nhands -on coding practice : https://codebasics.io/courses/machine -\\nlearning -for-data-science -beginners -to-advanced  \\n \\n• Core/Soft Skills  \\no Project Management  \\n▪ Scrum: https://scrumtrainingseries.com/  \\n▪ Kanban: https://youtu.be/jf0tlbt9lx0  \\n▪ Tools: JIRA, Notion  \\n• Assignment  \\n         ☐ Complete all exercises in ML playlist: https://bit.ly/3io5qqX  \\n         ☐ Work on 2 Kaggle ML notebooks  \\n         ☐ Write 2 LinkedIn posts  on whatever you have learnt in ML  \\n         ☐ Discord: Help people with at least 10 answers  \\n         ☐ Track B: Finish exercises and quizzes for relevant topics  \\n \\nWeek 22: ML Ops ⚙️ \\n \\n• Topics  \\no What is API? FastAPI for Python server development  \\no DevOps Fundamentals: CI/CD pipelines, containerization (Docker, Kubernetes)  \\no Familiarity with at least one cloud platform (AWS, Azure etc.)  \\n• Learning Resources  \\no Track  A: \\n▪ FastAPI tutorial: https://bit.ly/497p6Ex')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'codebasics.io  \\n \\n2 \\n• https://bit.ly/4at9Jaw  \\n• https://bit.ly/477IOOs  \\n• https://bit.ly/3GPD7dp  \\n \\n \\nWeek 1 and 2: Computer Science Fundamentals 💻 \\n \\n• Topics  \\no Data representation: Bits and Bytes, Storing text and numbers, Binary number \\nsystem.  \\no Basics of computer networks, IP addresses, Internet routing protocol  \\no UDP, TCP, HTTP, and The World Wide Web  \\no Programming basics: variables, strings, and numbers, if condition, loops  \\no Algorithm basics  \\n• Learning Resources  \\no Khan Academy  course: https://bit.ly/42DUXtW  \\no In the above course , only follow the first 4 sections (1) Digital Information (2) The \\nInternet (3) Programming (4) Algorithms . Completing the remaining sections is \\noptional . Do it if you have time and interest.  \\n \\nWeek 3 and 4: Beginners P ython                                                                \\n \\n• Topics  \\no Variables, Numbers, Strings  \\no Lists, Dictionaries, Sets, Tuples  \\no If condition, for loop  \\no Functions, Lambda Functions  \\no Modules  (pip install)  \\no Read, Write files \\no Exception handling  \\no Classes, Objects  \\n• Learning Resources  \\no Track A (Free)  \\n▪ Python Tutorials (Codebasics) on YouTube  (first 16  videos ) \\n- https://bit.ly/3X6CCC7  \\n▪ Corey’s Python Tutorials: https://bit.ly/3uqUgaZ  \\n▪ Codebasics python HINDI tutorials  \\n- https://bit.ly/3vmXrgw'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_results[3].page_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
